{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/chaitu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1924 samples, validate on 826 samples\n",
      "Epoch 1/20\n",
      "1924/1924 [==============================] - 1s 425us/step - loss: 1.8500 - accuracy: 0.2687 - val_loss: 1.7945 - val_accuracy: 0.3015\n",
      "Epoch 2/20\n",
      "1924/1924 [==============================] - 1s 323us/step - loss: 1.6458 - accuracy: 0.4054 - val_loss: 1.7073 - val_accuracy: 0.3584\n",
      "Epoch 3/20\n",
      "1924/1924 [==============================] - 1s 311us/step - loss: 1.4262 - accuracy: 0.5073 - val_loss: 1.6171 - val_accuracy: 0.3910\n",
      "Epoch 4/20\n",
      "1924/1924 [==============================] - 1s 317us/step - loss: 1.1745 - accuracy: 0.6320 - val_loss: 1.5650 - val_accuracy: 0.3947\n",
      "Epoch 5/20\n",
      "1924/1924 [==============================] - 1s 320us/step - loss: 0.9414 - accuracy: 0.7380 - val_loss: 1.5493 - val_accuracy: 0.4092\n",
      "Epoch 6/20\n",
      "1924/1924 [==============================] - 1s 340us/step - loss: 0.7538 - accuracy: 0.8035 - val_loss: 1.5653 - val_accuracy: 0.4104\n",
      "Epoch 7/20\n",
      "1924/1924 [==============================] - 1s 323us/step - loss: 0.6035 - accuracy: 0.8623 - val_loss: 1.5964 - val_accuracy: 0.4165\n",
      "Epoch 8/20\n",
      "1924/1924 [==============================] - 1s 347us/step - loss: 0.4931 - accuracy: 0.8846 - val_loss: 1.6417 - val_accuracy: 0.4165\n",
      "Epoch 9/20\n",
      "1924/1924 [==============================] - 1s 401us/step - loss: 0.4141 - accuracy: 0.9137 - val_loss: 1.7034 - val_accuracy: 0.4068\n",
      "Epoch 10/20\n",
      "1924/1924 [==============================] - 1s 389us/step - loss: 0.3497 - accuracy: 0.9220 - val_loss: 1.7598 - val_accuracy: 0.4140\n",
      "Epoch 11/20\n",
      "1924/1924 [==============================] - 1s 333us/step - loss: 0.3034 - accuracy: 0.9335 - val_loss: 1.8065 - val_accuracy: 0.4044\n",
      "Epoch 12/20\n",
      "1924/1924 [==============================] - 1s 329us/step - loss: 0.2569 - accuracy: 0.9511 - val_loss: 1.8768 - val_accuracy: 0.3983\n",
      "Epoch 13/20\n",
      "1924/1924 [==============================] - 1s 327us/step - loss: 0.2260 - accuracy: 0.9537 - val_loss: 1.9298 - val_accuracy: 0.3910\n",
      "Epoch 14/20\n",
      "1924/1924 [==============================] - 1s 321us/step - loss: 0.1996 - accuracy: 0.9600 - val_loss: 1.9942 - val_accuracy: 0.3983\n",
      "Epoch 15/20\n",
      "1924/1924 [==============================] - 1s 323us/step - loss: 0.1778 - accuracy: 0.9641 - val_loss: 2.0423 - val_accuracy: 0.3983\n",
      "Epoch 16/20\n",
      "1924/1924 [==============================] - 1s 321us/step - loss: 0.1542 - accuracy: 0.9693 - val_loss: 2.1086 - val_accuracy: 0.3935\n",
      "Epoch 17/20\n",
      "1924/1924 [==============================] - 1s 318us/step - loss: 0.1427 - accuracy: 0.9709 - val_loss: 2.1580 - val_accuracy: 0.3886\n",
      "Epoch 18/20\n",
      "1924/1924 [==============================] - 1s 335us/step - loss: 0.1328 - accuracy: 0.9740 - val_loss: 2.2119 - val_accuracy: 0.3947\n",
      "Epoch 19/20\n",
      "1924/1924 [==============================] - 1s 349us/step - loss: 0.1159 - accuracy: 0.9771 - val_loss: 2.2672 - val_accuracy: 0.3898\n",
      "Epoch 20/20\n",
      "1924/1924 [==============================] - 1s 353us/step - loss: 0.1054 - accuracy: 0.9823 - val_loss: 2.3193 - val_accuracy: 0.3826\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tweet_cluster_mapping.csv')\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "train_size = int(len(df) * .7)\n",
    "train_posts = df['tweet'][:train_size]\n",
    "train_tags = df['cluster_number'][:train_size]\n",
    "\n",
    "test_posts = df['tweet'][train_size:]\n",
    "test_tags = df['cluster_number'][train_size:]\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts)  # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179/1179 [==============================] - 0s 108us/step\n",
      "Test accuracy: 0.4088210463523865\n"
     ]
    }
   ],
   "source": [
    "# computing the accuracy score on the test data set\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
